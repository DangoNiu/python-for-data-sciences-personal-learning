{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17745c53",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=15%><img src=\"./img/UGA.png\"></img></td>\n",
    "<td><center><h1>Introduction to Python for Data Sciences</h1></center></td>\n",
    "<td width=15%><a href=\"https://tung-qle.github.io/\" style=\"font-size: 16px; font-weight: bold\">Quoc-Tung Le</a> </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8017c",
   "metadata": {},
   "source": [
    "# 1 - Pytorch: a Numpy library that can differentiate\n",
    "\n",
    "Pytorch is a Python library that are arguably the most popular for deep learning. It contains many similar functions that are implemented in Numpy (see the [second notebook](2_Numpy_and_co.ipynb)). Attention: many functions of these two libraries might have the same names, but their functionalities can be (entirely) different!\n",
    "\n",
    "As we will see in this tutorial, in comparison to Numpy, Pytorch provides an additional important feature: Automatic Differentiation (AD, sometimes shortened to autodiff). That means if we implement a function using Pytorch library, we can compute its gradient with respect to its parameters efficiently. The gradient will be then used in the optimization algorithm (see Optimization course for more details).\n",
    "\n",
    "The following code demonstrates the autodiff feature of Pytorch: in the following, we want to compute the gradient of the function:\n",
    "\n",
    "$$f(x) = \\frac{1}{2}x^\\top \\mathbf{A} x,$$\n",
    "\n",
    "which are given by: $\\nabla f(x) = \\frac{1}{2}(\\mathbf{A} + \\mathbf{A}^\\top)x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56b8060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.9299, -0.4740,  0.0187, -1.3583,  2.4464, -0.6302, -0.6530,  4.5564,\n",
      "         3.0746,  3.0185, -1.2823,  0.3387, -2.5504, -2.9233,  5.8600, -2.8698,\n",
      "        -0.3299, -0.1357,  0.0966, -1.9036])\n",
      "None\n",
      "Two vectors are equal. All is good\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "dim = 20\n",
    "# Create a parameter x and a matrix A\n",
    "x = torch.randn(dim, requires_grad=True)\n",
    "A = torch.randn((dim, dim))\n",
    "\n",
    "# Compute the function f(x) and assign to the variable y\n",
    "y = 0.5 * torch.dot(x, torch.matmul(A, x))\n",
    "\n",
    "# Differentiating the function f by calling y.backward()\n",
    "y.backward()\n",
    "\n",
    "# Accessing the gradient of f with respect to x\n",
    "print(x.grad)\n",
    "print(A.grad)\n",
    "\n",
    "# Checking the calculation with the closed form gradient formula\n",
    "try:\n",
    "    torch.testing.assert_close(0.5 * torch.matmul(A + A.T,x), x.grad)\n",
    "    print(\"Two vectors are equal. All is good\")\n",
    "except:\n",
    "    print(\"Wrong calculation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571b8bf",
   "metadata": {},
   "source": [
    "## 1.1 - How to create Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdeb76a",
   "metadata": {},
   "source": [
    "There are many different methods to create a Pytorch tensor, either using Python list, numpy array or even randomization. They are shown in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba1fdb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-3., -2., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize a tensor using Python list\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [-3.0, -2.0, -1.0]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9b8c8",
   "metadata": {},
   "source": [
    "Unlike a Numpy array, a Pytorch tensor has many metadata fields. The following code shows how to access the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad38f66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor info:\n",
      "  shape        : (2, 3)\n",
      "  size         : torch.Size([2, 3])\n",
      "  dtype        : torch.float32\n",
      "  device       : cpu\n",
      "  requires_grad: False\n",
      "  is_leaf      : True\n",
      "  data         :\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-3., -2., -1.]])\n"
     ]
    }
   ],
   "source": [
    "def show_info(x):\n",
    "    print(\"Tensor info:\")\n",
    "    print(f\"  shape        : {tuple(x.shape)}\")\n",
    "    print(f\"  size         : {x.size()}\")\n",
    "    print(f\"  dtype        : {x.dtype}\")\n",
    "    print(f\"  device       : {x.device}\")         # The output is either CPU or GPU, depending on the your implementation and hardware\n",
    "    print(f\"  requires_grad: {x.requires_grad}\")  # If requires_grad = False, it is impossible to differentiate a function w.r.t. x. See the example with the quadratic function\n",
    "    print(f\"  is_leaf      : {x.is_leaf}\")        # is_leaf = True if and only if requires_grad = False (convention) or it is initialized by the user and not a result of some operations\n",
    "    print(f\"  data         :\\n{x}\")    \n",
    "\n",
    "show_info(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493eb2df",
   "metadata": {},
   "source": [
    "One can manually assign specific values for these metadata fields right at the moment or after creation.\n",
    "\n",
    "Pay attention to the field _requires\\_grad_ : it determines whether a variable can be differentiated or not. Therefore, when using Pytorch to perform optimization tasks, you need to ensure that _requires\\_grad_ is __True__. Otherwise, the parameter will never be updated (we will see more about this in the exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4880c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor info:\n",
      "  shape        : (2, 3)\n",
      "  size         : torch.Size([2, 3])\n",
      "  dtype        : torch.float16\n",
      "  device       : cpu\n",
      "  requires_grad: True\n",
      "  is_leaf      : False\n",
      "  data         :\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-3., -2., -1.]], dtype=torch.float16, grad_fn=<ToCopyBackward0>)\n",
      "Tensor info:\n",
      "  shape        : (2, 3)\n",
      "  size         : torch.Size([2, 3])\n",
      "  dtype        : torch.float16\n",
      "  device       : cpu\n",
      "  requires_grad: True\n",
      "  is_leaf      : True\n",
      "  data         :\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-3., -2., -1.]], dtype=torch.float16, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# We modify several metadata field of the same tensor x that we created previously\n",
    "\n",
    "x.requires_grad = True\n",
    "x = x.to(dtype = torch.float16)\n",
    "\n",
    "show_info(x)\n",
    "# We can also create a new tensor x, with desired metadata \n",
    "y = torch.tensor([[1, 2, 3], [-3, -2, -1]], requires_grad = True, dtype = torch.float16)\n",
    "show_info(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b820b",
   "metadata": {},
   "source": [
    "One can use a Numpy array as the value of a newly-created Pytorch tensor as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor using Numpy arrays\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_array = np.reshape(np.arange(20), (4,5))\n",
    "x = torch.Tensor(x_array)\n",
    "print(x_array)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff205675",
   "metadata": {},
   "source": [
    "Finally, Pytorch offers several methods of creating random or special tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7b51496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6433, 0.1101],\n",
      "        [0.8081, 0.0404],\n",
      "        [0.8471, 0.4355]])\n",
      "torch.Size([3, 2])\n",
      "tensor([[-0.3327, -2.7870],\n",
      "        [-2.6802,  0.7631],\n",
      "        [-0.0599, -1.4182]])\n",
      "torch.Size([3, 2])\n",
      "All ones matrix:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "All zeros matrix:\n",
      " tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Identity matrix:\n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor by randomization\n",
    "\n",
    "# Using uniform distribution\n",
    "x = torch.rand((3,2))\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "# Using Gaussian distribution\n",
    "x = torch.randn((3,2))\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "# Creat an identity, all-one and all-zero matrices\n",
    "x_all_ones = torch.ones((3,2))\n",
    "x_all_zeros = torch.zeros((3,2))\n",
    "x_identity = torch.eye(3)  \n",
    "\n",
    "print(\"All ones matrix:\\n {}\".format(x_all_ones))\n",
    "print(\"All zeros matrix:\\n {}\".format(x_all_zeros))\n",
    "print(\"Identity matrix:\\n {}\".format(x_identity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3abe1",
   "metadata": {},
   "source": [
    "## 1.2 - Operation on Pytorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd2b66",
   "metadata": {},
   "source": [
    "Pytorch provides a plethora of tensor operations. For a complete presentation of its functionalities, you are advised to visit [this Pytorch documentation](https://docs.pytorch.org/docs/stable/torch.html). In the following, we will only introduce several frequent operations.\n",
    "\n",
    "### 1.2.1 - Slicing, Joining and Mutating Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31d18c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]) \n",
      "\n",
      "Reshape to a matrix 10 x 10:\n",
      " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
      "        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
      "        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
      "        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n",
      "\n",
      "Reshape to a tensor of dimensions 2 x 5 x 5 x 2: \n",
      " tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5],\n",
      "          [ 6,  7],\n",
      "          [ 8,  9]],\n",
      "\n",
      "         [[10, 11],\n",
      "          [12, 13],\n",
      "          [14, 15],\n",
      "          [16, 17],\n",
      "          [18, 19]],\n",
      "\n",
      "         [[20, 21],\n",
      "          [22, 23],\n",
      "          [24, 25],\n",
      "          [26, 27],\n",
      "          [28, 29]],\n",
      "\n",
      "         [[30, 31],\n",
      "          [32, 33],\n",
      "          [34, 35],\n",
      "          [36, 37],\n",
      "          [38, 39]],\n",
      "\n",
      "         [[40, 41],\n",
      "          [42, 43],\n",
      "          [44, 45],\n",
      "          [46, 47],\n",
      "          [48, 49]]],\n",
      "\n",
      "\n",
      "        [[[50, 51],\n",
      "          [52, 53],\n",
      "          [54, 55],\n",
      "          [56, 57],\n",
      "          [58, 59]],\n",
      "\n",
      "         [[60, 61],\n",
      "          [62, 63],\n",
      "          [64, 65],\n",
      "          [66, 67],\n",
      "          [68, 69]],\n",
      "\n",
      "         [[70, 71],\n",
      "          [72, 73],\n",
      "          [74, 75],\n",
      "          [76, 77],\n",
      "          [78, 79]],\n",
      "\n",
      "         [[80, 81],\n",
      "          [82, 83],\n",
      "          [84, 85],\n",
      "          [86, 87],\n",
      "          [88, 89]],\n",
      "\n",
      "         [[90, 91],\n",
      "          [92, 93],\n",
      "          [94, 95],\n",
      "          [96, 97],\n",
      "          [98, 99]]]])\n",
      "Same results\n"
     ]
    }
   ],
   "source": [
    "# Torch reshape\n",
    "x = torch.tensor([i for i in range(100)])\n",
    "print(\"Original tensor:\\n {} \\n\".format(x))\n",
    "\n",
    "# Reshape x to (10,10)\n",
    "x_reshaped_1 = torch.reshape(x, (10, 10))\n",
    "print(\"Reshape to a matrix 10 x 10:\\n {}\\n\".format(x_reshaped_1))\n",
    "\n",
    "# Reshape x to (2, 5, 5, 2)\n",
    "x_reshaped_2 = torch.reshape(x, (2, 5, 5, 2))\n",
    "print(\"Reshape to a tensor of dimensions 2 x 5 x 5 x 2: \\n {}\".format(x_reshaped_2))\n",
    "\n",
    "# You can also obtain the same result using x_reshape_1\n",
    "\n",
    "try:\n",
    "    torch.testing.assert_close(x_reshaped_2, torch.reshape(x_reshaped_1, (2,5,5,2)))\n",
    "    print(\"Same results\")\n",
    "except:\n",
    "    print(\"Different results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8da23494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "First method:\n",
      " tensor([[0, 5],\n",
      "        [1, 6],\n",
      "        [2, 7],\n",
      "        [3, 8],\n",
      "        [4, 9]])\n",
      "Second method:\n",
      " tensor([[0, 5],\n",
      "        [1, 6],\n",
      "        [2, 7],\n",
      "        [3, 8],\n",
      "        [4, 9]])\n",
      "torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# Torch dimension transpose and permutation \n",
    "x = torch.arange(10).reshape((2,5))\n",
    "print(x)\n",
    "\n",
    "# For 2D tensor, transpose can be simply done by\n",
    "x_transpose_1 = x.T\n",
    "print(\"First method:\\n {}\".format(x_transpose_1))\n",
    "\n",
    "# For general tensor with multiple dimension, use torch.transpose(your_tensor, dim0, dim1)\n",
    "# dim0, dim1: two dimensions that you want to switch\n",
    "x_transpose_2 = torch.transpose(x, 0, 1)\n",
    "print(\"Second method:\\n {}\".format(x_transpose_2))\n",
    "\n",
    "x_3d_tensor = torch.arange(30).reshape((2,3,5))\n",
    "x_transpose_3 = torch.permute(x_3d_tensor, (1,2,0))\n",
    "print(x_transpose_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2bef247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the first new concatenated tensor: torch.Size([8, 5])\n",
      "Size of the second new concatenated tensor: torch.Size([5, 8])\n"
     ]
    }
   ],
   "source": [
    "# Torch concatenate\n",
    "# Concatenate a matrix 2 x 5 with another of size 6 x 5 to get a 8 x 5 matrix\n",
    "x = torch.arange(10).reshape((2,5))\n",
    "y = torch.arange(30).reshape((6,5))\n",
    "z = torch.concat([x,y], dim = 0)\n",
    "print(\"Size of the first new concatenated tensor: {}\".format(z.size()))\n",
    "\n",
    "# Concatenate a matrix 5 x 2 with another of size 5 x 6 to get a 5 x 8 matrix\n",
    "x = torch.arange(10).reshape((5,2))\n",
    "y = torch.arange(30).reshape((5,6))\n",
    "z = torch.concat([x,y], dim = 1)\n",
    "print(\"Size of the second new concatenated tensor: {}\".format(z.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b3c80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 2])\n",
      "torch.Size([3, 5, 2])\n",
      "torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# Torch stack\n",
    "# In comparison to torch concatenate, torch stack creates a new tensor with one more dimension\n",
    "\n",
    "tensor_list = [torch.randn(3,2) for i in range(5)]\n",
    "tensor_stacked_0 = torch.stack(tensor_list, dim = 0)\n",
    "tensor_stacked_1 = torch.stack(tensor_list, dim = 1)\n",
    "tensor_stacked_2 = torch.stack(tensor_list, dim = 2)\n",
    "\n",
    "print(tensor_stacked_0.size())\n",
    "print(tensor_stacked_1.size())\n",
    "print(tensor_stacked_2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7698d08b",
   "metadata": {},
   "source": [
    "### 1.2.2 - Pointwise Operations\n",
    "\n",
    "Similar to Numpy, Pytorch has many different function for pointwise operations, i.e., those of the forms:\n",
    "\n",
    "$$\\begin{pmatrix} x_{i_1\\ldots i_n} \\end{pmatrix}_{i_1,\\ldots,i_n} \\mapsto \\begin{pmatrix} f(x_{i_1\\ldots i_n}) \\end{pmatrix}_{i_1,\\ldots,i_n} \\qquad \\text{or} \\qquad \\begin{pmatrix} x_{i_1\\ldots i_n} \\end{pmatrix}_{i_1,\\ldots,i_n} \\times \\begin{pmatrix} y_{i_1\\ldots i_n} \\end{pmatrix}_{i_1,\\ldots,i_n} \\mapsto \\begin{pmatrix} g(x_{i_1\\ldots i_n}, y_{i_1\\ldots i_n}) \\end{pmatrix}_{i_1,\\ldots,i_n}$$\n",
    "\n",
    "where $f: \\mathbb{R} \\to \\mathbb{R}$ and $g: \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2950, -2.2121,  0.5332, -0.5436,  0.9198],\n",
      "        [-0.6403, -1.1062,  0.6193,  0.2440,  0.7453],\n",
      "        [ 0.3132, -0.3966,  0.8940,  0.8641,  1.7163]])\n",
      "tensor([[ 0.2907, -0.8013,  0.5083, -0.5172,  0.7955],\n",
      "        [-0.5974, -0.8940,  0.5805,  0.2416,  0.6782],\n",
      "        [ 0.3081, -0.3863,  0.7796,  0.7605,  0.9894]])\n",
      "tensor([[ 0.9568, -0.5983,  0.8612,  0.8558,  0.6060],\n",
      "        [ 0.8019,  0.4481,  0.8143,  0.9704,  0.7349],\n",
      "        [ 0.9513,  0.9224,  0.6263,  0.6493, -0.1450]])\n",
      "tensor([[0.2950, 0.0000, 0.5332, 0.0000, 0.9198],\n",
      "        [0.0000, 0.0000, 0.6193, 0.2440, 0.7453],\n",
      "        [0.3132, 0.0000, 0.8940, 0.8641, 1.7163]])\n",
      "tensor([[0.2950, 2.2121, 0.5332, 0.5436, 0.9198],\n",
      "        [0.6403, 1.1062, 0.6193, 0.2440, 0.7453],\n",
      "        [0.3132, 0.3966, 0.8940, 0.8641, 1.7163]])\n",
      "tensor([[1.3431, 0.1095, 1.7044, 0.5806, 2.5087],\n",
      "        [0.5272, 0.3308, 1.8577, 1.2764, 2.1070],\n",
      "        [1.3678, 0.6726, 2.4450, 2.3729, 5.5637]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,5)\n",
    "\n",
    "# f(x) = sin(x), cos(x), ReLU(x), |x|, exponent\n",
    "\n",
    "print(x)\n",
    "print(torch.sin(x))\n",
    "print(torch.cos(x))\n",
    "print(torch.relu(x))\n",
    "print(torch.abs(x))\n",
    "print(torch.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8982779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value:\n",
      " tensor([[-0.7299, -1.5813,  0.1297, -0.8237,  0.5331],\n",
      "        [ 0.9853,  0.1155, -1.3892,  1.4084,  0.6984],\n",
      "        [ 1.4100, -0.7215,  1.0117,  1.2595,  1.7525]])\n",
      "New value:\n",
      " tensor([[-0.6668, -0.9999,  0.1294, -0.7336,  0.5082],\n",
      "        [ 0.8334,  0.1153, -0.9836,  0.9868,  0.6430],\n",
      "        [ 0.9871, -0.6605,  0.8477,  0.9519,  0.9835]])\n"
     ]
    }
   ],
   "source": [
    "# Note that these previous functions do not change the value of x. In fact, they will compute the value f(x) and save it to a new memory allocation\n",
    "# We can compute the function in-place by adding _ at the end of these functions\n",
    "\n",
    "x = torch.randn(3,5)\n",
    "print(\"Original value:\\n {}\".format(x))\n",
    "torch.sin_(x)\n",
    "print(\"New value:\\n {}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ff147d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4660, -0.6406, -1.3284,  2.3999, -0.3675],\n",
      "        [-0.8461, -2.2814,  0.0337,  0.9836, -0.1036],\n",
      "        [ 0.7977, -1.7252,  0.6651,  1.0309, -2.0270]])\n",
      "tensor([[-1.7531, -3.7535,  0.7771,  2.8292, -0.1012],\n",
      "        [ 0.3928,  0.3413,  1.0025, -1.1508, -0.7393],\n",
      "        [-0.6586, -0.8763, -0.4916, -2.5989,  0.0535]])\n",
      "tensor([[ 0.7520, -3.4196,  0.2902, -0.5613,  0.0312],\n",
      "        [ 0.1404,  1.2721, -0.2510, -0.0892, -0.1340],\n",
      "        [ 0.0507,  0.5521,  0.0502, -1.4229,  1.0264]])\n",
      "tensor([[  5.9176,  -1.4116,   0.2619, -12.1791,   1.7601],\n",
      "        [  0.3659,   0.7397,  -1.0696,  -0.0783,  -1.3258],\n",
      "        [  0.0955,   3.0645,   0.1499,  -0.4320,   0.9486]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,5)\n",
    "y = torch.randn(3,5)\n",
    "\n",
    "# g(x, y) = x + y, x - y, x * y, x / y\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6176973",
   "metadata": {},
   "source": [
    "In the previous example, noticing that $x$ and $y$ share the same shapes. However, it is also possible to perform operations for $x$ and $y$ of different shapes under certain conditions. Broadcasting allows to reduce memory footprint, simplify code and optimized performance.\n",
    "\n",
    "Consider $x \\in \\mathbb{R}^{3 \\times 5}$ and $y \\in \\mathbb{R}^{5}$. The value of $x + y$ will be given by $x + y^\\star$ where $y^\\star \\in \\mathbb{R}^{3 \\times 5}$ is a matrix whose rows are all equal to $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "315bef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8343, -1.3276, -0.1556, -2.9641,  0.3843],\n",
      "        [-1.7685, -1.1395, -0.1941, -0.3524, -0.7120],\n",
      "        [-0.0455, -2.1708, -0.1397, -1.9597, -0.1432]])\n",
      "tensor([[-1.8343, -1.3276, -0.1556, -2.9641,  0.3843],\n",
      "        [-1.7685, -1.1395, -0.1941, -0.3524, -0.7120],\n",
      "        [-0.0455, -2.1708, -0.1397, -1.9597, -0.1432]])\n",
      "tensor([[-1.9162, -1.5888, -0.8377, -2.8165, -0.9353],\n",
      "        [ 0.1495,  0.5992,  1.1237,  1.7951, -0.0318],\n",
      "        [-0.3130, -2.6175, -1.0074, -1.9976, -1.6484]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,5)\n",
    "y = torch.randn(5)\n",
    "\n",
    "# Use broadcasting\n",
    "print(x + y)\n",
    "\n",
    "# More explicit code, but lengthy and not memory efficient because we need to explicitly compute y*\n",
    "print(x + torch.stack([y for i in range(3)], dim = 0))\n",
    "\n",
    "# If you want to add a certain vector to all columns, then do the following\n",
    "z = torch.randn(3)\n",
    "\n",
    "# First, reshape the vector to (3,1). Pytorch broadcasting will handle the rest\n",
    "z = z.reshape((3,1))\n",
    "print(x + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa335a1",
   "metadata": {},
   "source": [
    "### 1.2.3 - Matrix and Tensor Operations\n",
    "\n",
    "Dot product between two tensors - $\\mathtt{torch.dot}$ and tensor norm - $\\mathtt{torch.norm}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb355c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a13ed07a",
   "metadata": {},
   "source": [
    "Matrix-matrix and matrix-vector multiplicaiton - $\\mathtt{torch.matmul}$ and its batch version - $\\mathtt{torch.bmm}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73648d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9a6502",
   "metadata": {},
   "source": [
    "Matrix inversion - $\\mathtt{torch.inverse}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d5583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8f5b1c",
   "metadata": {},
   "source": [
    "Singular Value Decomposition: Given a matrix $\\mathbf{A}$ (of arbitrary dimension), it can always be written as:\n",
    "\n",
    "$$\\mathbf{A} = \\mathbf{U}\\mathbf{D}\\mathbf{V}^\\top$$\n",
    "\n",
    "where $\\mathbf{U}, \\mathbf{V}$ are orthogonal and $\\mathbf{D}$ is a (possibly rectangular) diagonal matrix. Pytorch allows to compute such decomposition with $\\mathtt{torch.svd}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95cb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "582bf51c",
   "metadata": {},
   "source": [
    "## 1.3 - Compute the gradient of a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed4e15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0cd9602",
   "metadata": {},
   "source": [
    "# 2 - Several Pytorch modules for neural networks training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4646dd9",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa96438a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
